{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "colab": {
   "name": "DM_Assignment_5_120210183_강수연.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "Hi0HXI_9M8lY",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f33afda4-e48f-4950-9628-010fb3480132",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    " !pip install einops"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hc6X4fRDKP-j",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#구현하는 모델에서 쓰이는 모든 activation함수는 정의하여 드린 GELU 함수를 사용해야함.\n",
    "#MultiHeadAttention에서 Head로 나눌때, 이미지를 patch로자른후 sequence로 만들때 Rearrange함수를 사용하면 편리함.(사용하지 않으셔도 됩니다)\n",
    "#CIFAR10에 대한 test accuracy가 60프로 이상인 ViT모델을 만드시오.\n",
    "import tensorflow as tf\n",
    "from einops.layers.tensorflow import Rearrange\n",
    "from tensorflow.keras.activations import gelu\n",
    "GELU = lambda x : gelu(x)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QrJci74oNV2m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#논문[1]에서 설명하는 MultiHeadAttention을 만들어라.\n",
    "class MultiHeadedAttention(tf.keras.Model):\n",
    "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension)\n",
    "    def __init__(self, dimension, heads=8):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        ############Write your code Here############\n",
    "        self.heads = heads\n",
    "        self.scale = dimension ** -0.5\n",
    "        self.qkv = tf.keras.layers.Dense(dimension * 3, use_bias=False)\n",
    "        self.dense = tf.keras.layers.Dense(dimension)\n",
    "        self.rearrange_qkv = Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=self.heads)\n",
    "        self.rearrange_dense = Rearrange('b h n d -> b n (h d)')\n",
    "        ############################################\n",
    "    def call(self, inputs):\n",
    "        output = None\n",
    "        ############Write your code Here############\n",
    "        qkv = self.qkv(inputs)\n",
    "        qkv = self.rearrange_qkv(qkv)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        matmul = tf.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
    "        attn = tf.nn.softmax(matmul, axis=-1)\n",
    "\n",
    "        dense = tf.einsum('bhij,bhjd->bhid', attn, v)\n",
    "        dense = self.rearrange_dense(dense)\n",
    "        output = self.dense(dense)\n",
    "        ############################################\n",
    "        return output\n",
    "\n",
    "#인자로 받은 residual_function을 사용하여 real_function값을 return하여주는 Class를 만들어라.(call함수 참고)\n",
    "class ResidualBlock(tf.keras.Model):\n",
    "    def __init__(self, residual_function):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        ############Write your code Here############\n",
    "        self.residual_function = residual_function\n",
    "        ############################################\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.residual_function(inputs) + inputs\n",
    "\n",
    "#인자로 받은 normfunction에 들어가기전에 LayerNormalization을 해주는 Class를 만들어라.(call함수 참고)\n",
    "class NormalizationBlock(tf.keras.Model):\n",
    "    def __init__(self, norm_function, epsilon=1e-5):\n",
    "        super(NormalizationBlock, self).__init__()\n",
    "        ############Write your code Here############\n",
    "        self.norm_function = norm_function\n",
    "        self.normalize = tf.keras.layers.LayerNormalization(epsilon=epsilon)\n",
    "        ############################################\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.norm_function(self.normalize(inputs))\n",
    "\n",
    "#논문[1]에서의 MLPBlock을 만들어라.\n",
    "class MLPBlock(tf.keras.Model):\n",
    "    #output_dimension - MLPBlock의 output dimension\n",
    "    #hidden_dimension - MLPBlock의 hidden layer dimension\n",
    "    def __init__(self, output_dimension, hidden_dimension):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        ############Write your code Here############\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(hidden_dimension, activation=GELU),\n",
    "             tf.keras.layers.Dense(output_dimension)]\n",
    "        )\n",
    "        ############################################\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = None\n",
    "        ############Write your code Here############\n",
    "        output = self.ffn(inputs)\n",
    "        ############################################\n",
    "        return output\n",
    "\n",
    "#논문[1]을 읽고 TransformerEncoder를 위에서 정의한 class들을 사용하여 만들어라.\n",
    "class TransformerEncoder(tf.keras.Model):\n",
    "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension), heads - MHA에서 head의 개수\n",
    "    #depth - encoder layer의 개수, mlp_dimension - MLP block의 hidden layer의 dimension\n",
    "    def __init__(self, dimension, depth, heads, mlp_dimension): \n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        layers_ = []\n",
    "        for _ in range(depth):\n",
    "            ############Write your code Here############  \n",
    "            layers_.extend([\n",
    "                ResidualBlock(NormalizationBlock(MultiHeadedAttention(dimension, heads))),\n",
    "                ResidualBlock(NormalizationBlock(MLPBlock(dimension, mlp_dimension)))\n",
    "            ])\n",
    "            ############################################\n",
    "        self.layers_ = tf.keras.Sequential(layers_)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.layers_(inputs)\n",
    "\n",
    "#논문[2]를 읽고 ViT모델을 위에서 정의한 class들을 사용하여 만들어라.\n",
    "class ImageTransformer(tf.keras.Model):\n",
    "    #image_size - 이미지의 W==H의 크기(int), patch_size - 이미지를 쪼갤 patch의 크기(int)\n",
    "    #n_classes - 최종 class의 개수, batch_size - 배치사이즈\n",
    "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension), depth - encoder layer의 개수\n",
    "    #heads - MHA에서 head의 개수, mlp_dimension - MLP block의 hidden layer의 dimension\n",
    "    #channel - input image에 대한 channel의 수\n",
    "    def __init__(\n",
    "            self, image_size, patch_size, n_classes, batch_size,\n",
    "            dimension, depth, heads, mlp_dimension, channels=3):\n",
    "        super(ImageTransformer, self).__init__()\n",
    "        assert image_size % patch_size == 0, 'invalid patch size for image size'\n",
    "\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        self.patch_size = patch_size\n",
    "        self.dimension = dimension\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.positional_embedding = self.add_weight(\n",
    "            \"position_embeddings\", shape=[num_patches + 1, dimension],\n",
    "            initializer=tf.keras.initializers.RandomNormal(), dtype=tf.float32\n",
    "        )\n",
    "        self.classification_token = self.add_weight(\n",
    "            \"classification_token\", shape=[1, 1, dimension],\n",
    "            initializer=tf.keras.initializers.RandomNormal(), dtype=tf.float32\n",
    "        )\n",
    "        ############Write your code Here############\n",
    "        self.patch_dim = channels * patch_size ** 2\n",
    "        self.patch_proj = tf.keras.layers.Dense(dimension)\n",
    "        self.enc_layers = TransformerEncoder(dimension, depth, heads, mlp_dimension)   \n",
    "        self.mlp_head = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(mlp_dimension, activation=GELU),\n",
    "             tf.keras.layers.Dropout(0.1),\n",
    "             tf.keras.layers.Dense(n_classes)]\n",
    "        )          \n",
    "        self.rearrange = Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=self.patch_size, p2=self.patch_size)    \n",
    "        self.to_classification_token = tf.identity       \n",
    "        ############################################\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = None\n",
    "        ############Write your code Here############\n",
    "        shapes = tf.shape(inputs)\n",
    "        x = self.rearrange(inputs)\n",
    "        x = self.patch_proj(x)\n",
    "        classification_token = tf.broadcast_to(self.classification_token, [shapes[0], 1, self.dimension])\n",
    "        x = tf.concat((classification_token, x), axis=1)\n",
    "        x += self.positional_embedding\n",
    "        x = self.enc_layers(x)\n",
    "        x = self.to_classification_token(x[:, 0])\n",
    "        output = self.mlp_head(x)\n",
    "        ############################################\n",
    "        return output"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cAydwOELeFba",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7a701514-2102-4437-afdb-39b45845dd50",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from tensorflow.keras import datasets\n",
    "# Download and prepare the CIFAR10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "############Write your code Here############\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "############################################\n",
    "# Make image shape (BS, H, W, C) to (BS, C, H, W)\n",
    "############Write your code Here############\n",
    "train_images= tf.transpose(train_images, perm=[0, 3, 1, 2])\n",
    "test_images= tf.transpose(test_images, perm=[0, 3, 1, 2])\n",
    "############################################\n",
    "\n",
    "#Initialize your model\n",
    "#Initialize optimizer and loss and compile it to the model\n",
    "############Write your code Here############\n",
    "model = ImageTransformer(image_size=32, patch_size=4, n_classes=10, batch_size=200, \n",
    "                         dimension=64, depth=3, heads=4, mlp_dimension=128)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "############################################\n",
    "\n",
    "#Train your model\n",
    "############Write your code Here############\n",
    "history = model.fit(train_images, train_labels, batch_size=200, epochs=30)\n",
    "############################################\n",
    "print('==============Training Finished===============')\n",
    "\n",
    "#Evaluate your test samples\n",
    "accuracy = 0\n",
    "############Write your code Here############\n",
    "accuracy = model.evaluate(test_images, test_labels, batch_size=200)\n",
    "############################################\n",
    "\n",
    "print('Test Accuracy :', accuracy)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "250/250 [==============================] - 8s 24ms/step - loss: 1.8668 - accuracy: 0.2982\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 1.5004 - accuracy: 0.4480\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 1.3396 - accuracy: 0.5109\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 1.2608 - accuracy: 0.5437\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 1.1943 - accuracy: 0.5700\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 1.1555 - accuracy: 0.5833\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 1.1098 - accuracy: 0.6018\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 1.0722 - accuracy: 0.6163\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 1.0398 - accuracy: 0.6281\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 1.0014 - accuracy: 0.6403\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.9763 - accuracy: 0.6500\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.9501 - accuracy: 0.6593\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.9221 - accuracy: 0.6708\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.8903 - accuracy: 0.6815\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.8672 - accuracy: 0.6901\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.8483 - accuracy: 0.6929\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.8280 - accuracy: 0.7023\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.8011 - accuracy: 0.7098\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.7746 - accuracy: 0.7223\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.7511 - accuracy: 0.7291\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.7303 - accuracy: 0.7364\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.7072 - accuracy: 0.7435\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.6940 - accuracy: 0.7473\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.6683 - accuracy: 0.7577\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.6507 - accuracy: 0.7650\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.6302 - accuracy: 0.7726\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.6117 - accuracy: 0.7761\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.6021 - accuracy: 0.7816\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.5676 - accuracy: 0.7928\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.5571 - accuracy: 0.7975\n",
      "==============Training Finished===============\n",
      "50/50 [==============================] - 1s 9ms/step - loss: 1.3632 - accuracy: 0.6009\n",
      "Test Accuracy : [1.3631728887557983, 0.6008999943733215]\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}